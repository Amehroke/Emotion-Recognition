[
    {
        "file_name": "notebooks/librosa_balanced.csv",
        "model_name": "KNeighborsClassifier",
        "model_params": {
            "algorithm": "auto",
            "leaf_size": 30,
            "metric": "manhattan",
            "metric_params": null,
            "n_jobs": null,
            "n_neighbors": 3,
            "p": 2,
            "weights": "distance"
        },
        "accuracy": 0.6418539325842697,
        "classification_report": {
            "0": {
                "precision": 0.6839378238341969,
                "recall": 0.7135135135135136,
                "f1-score": 0.6984126984126984,
                "support": 185.0
            },
            "1": {
                "precision": 0.5257142857142857,
                "recall": 0.45320197044334976,
                "f1-score": 0.48677248677248675,
                "support": 203.0
            },
            "2": {
                "precision": 0.5531914893617021,
                "recall": 0.49056603773584906,
                "f1-score": 0.52,
                "support": 212.0
            },
            "3": {
                "precision": 0.5909090909090909,
                "recall": 0.4482758620689655,
                "f1-score": 0.5098039215686274,
                "support": 203.0
            },
            "4": {
                "precision": 0.7733333333333333,
                "recall": 0.8446601941747572,
                "f1-score": 0.8074245939675174,
                "support": 206.0
            },
            "5": {
                "precision": 0.6591928251121076,
                "recall": 0.6681818181818182,
                "f1-score": 0.6636568848758465,
                "support": 220.0
            },
            "6": {
                "precision": 0.6541353383458647,
                "recall": 0.8923076923076924,
                "f1-score": 0.754880694143167,
                "support": 195.0
            },
            "accuracy": 0.6418539325842697,
            "macro avg": {
                "precision": 0.6343448838015115,
                "recall": 0.6443867269179923,
                "f1-score": 0.6344216113914777,
                "support": 1424.0
            },
            "weighted avg": {
                "precision": 0.6336833692256509,
                "recall": 0.6418539325842697,
                "f1-score": 0.6329263177580814,
                "support": 1424.0
            }
        }
    }
]